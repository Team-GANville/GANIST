{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "",
   "metadata": {
    "tags": [],
    "cell_id": "00002-a3960d36-4e23-4878-95ce-a809883232f0",
    "is_code_hidden": true,
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00002-d48aaa4f-e3c4-4bfd-80c2-fa21d30abf72",
    "is_code_hidden": false,
    "deepnote_to_be_reexecuted": false,
    "source_hash": "8ebf4d8d",
    "execution_start": 1624451028116,
    "execution_millis": 3,
    "deepnote_cell_type": "code"
   },
   "source": "# 1. batch_size :  The number of samples to train use in one iteration\n# 2. epochs : The number of times the network goes through the enitre training dataset.\n# 3. Sample_size : [speculation] The number of images[random noise] used in training for generator.\n# 4. nz :[speculation] input feature size for each sample[image] in above sample_size.\n# 5. k : hyper-parameter\n# 6. device : utilizing GPU if available ",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Dependencies",
   "metadata": {
    "tags": [],
    "cell_id": "00002-84fbcf29-7ceb-40cd-8c10-2131edae520e",
    "deepnote_cell_type": "text-cell-h2"
   }
  },
  {
   "cell_type": "markdown",
   "source": "1. Tqdm :  provides progress bar.\n2. Transform : provides common image transform algorithms.\n3. make_grid : Make a grid of images.\n4. DataLoader: helps in importing training and test sets ",
   "metadata": {
    "tags": [],
    "cell_id": "00003-be2aa102-9fc3-48a7-afee-0c87b9dd8365",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00009-36dedc80-7016-432e-8cab-d284b2ef7735",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4354564f",
    "execution_start": 1624451028129,
    "execution_millis": 1947,
    "deepnote_cell_type": "code"
   },
   "source": "import torch \nfrom torch import nn\nfrom tqdm.auto import tqdm\nfrom torchvision import transforms\nfrom torchvision.datasets import MNIST\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\ntorch.manual_seed(0)",
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 2,
     "data": {
      "text/plain": "<torch._C.Generator at 0x7f9803a17bd0>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "\nTensor:\n\n    1. Tensors are n-dimnesional matrix or vertices.\n    2. Pytorch use tensor operations.\n\nBatches:\n\n    1. Batches are the amount of training samples the model performs operation during a single execution.\n    2. Batch values are usually chosen to be multiples of 2 (32,64,128,256,512).\n\nSumamry :\n    1. https://stackoverflow.com/questions/42480111/model-summary-in-pytorch",
   "metadata": {
    "tags": [],
    "cell_id": "00004-537e6a70-478b-4b63-9e18-56fc3313a624",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "# Dataset\n\n    1. The Dataset is downloaded from the MNIST website . Furtherthe data is divided\n       into batches , converted from PIL to tensors using DataLoaders.\n    2. Dataloader encloses a iterable wrapper over the tensor object using which we\n       can access each batch.\n    3. Structure : 469 batches -> each containg 128 images -> each image  [1,28,28]",
   "metadata": {
    "tags": [],
    "cell_id": "00006-03e85427-fae3-4240-a248-15b664a8257e",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00007-0c5e8c5c-b2ce-4c85-85d0-ffa2d69f7d2b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "80897178",
    "execution_start": 1624451030080,
    "execution_millis": 5,
    "deepnote_cell_type": "code"
   },
   "source": "loss_func = nn.BCEWithLogitsLoss()\nepochs = 200\nbatch_size = 128\nlr = 0.0001\nz_dim = 64\ndevice = 'cuda'",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00004-482a4e69-1bab-4f81-a5cc-a1503dc077b0",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "277fa9d0",
    "execution_start": 1624451030092,
    "execution_millis": 234,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "dataloader = DataLoader( MNIST(\"/work/basicGAN/GAN_cadmus/input\",download = False,transform = transforms.ToTensor() )\n                ,batch_size = batch_size , shuffle = True)",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "text": "/shared-libs/python3.7/py/lib/python3.7/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00009-79bf1256-722d-4406-8a4b-cbde57e66fae",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "fd8ef7e3",
    "execution_start": 1624451030329,
    "execution_millis": 5,
    "deepnote_cell_type": "code"
   },
   "source": "def show_tensor_images(image_tensor,num_images=25,size = (1,28,28)):\n\n    image_unflat = image_tensor.detach().cpu().view(-1, *size)\n    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n    plt.show()",
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### The Generator",
   "metadata": {
    "tags": [],
    "cell_id": "00010-c211dd35-8130-4a19-8e3c-0dc0cf6e023a",
    "deepnote_cell_type": "text-cell-h3"
   }
  },
  {
   "cell_type": "markdown",
   "source": "batch norm - batch normalization lagta hai har ek feature pe ya column pe. Toh usko bas columns chahiye as argument. \nAb gan generator kam hai ki bas layout prepare kare , isse input featurs aur output features set ho jaate hai . Baaki num of sample baadmai pass karne ke time bhejna hota hai. yaha pe 10 feature ke vector ko humne 28*28 pe scale kar diya,",
   "metadata": {
    "tags": [],
    "cell_id": "00011-9165a133-c406-46a1-ba9d-d412b25ee439",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00009-e692a332-f099-49f8-b942-0551dcd2ca9b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "7e74f704",
    "execution_start": 1624452670297,
    "execution_millis": 8,
    "deepnote_cell_type": "code"
   },
   "source": "def create_gan_layer(input_dim,output_dim):\n    \n    return nn.Sequential(\n\n        nn.Linear(input_dim,output_dim),\n        nn.BatchNorm1d(output_dim),\n        nn.ReLU(inplace = False)\n    )",
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00011-53360c5f-6bc8-4870-aa2a-5564a25755a4",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "e2bf672c",
    "execution_start": 1624451030351,
    "execution_millis": 6,
    "deepnote_cell_type": "code"
   },
   "source": "class Generator(nn.Module):\n\n    def __init__(self,z_dim,hidden_dim,image_dim):\n\n        super(Generator,self).__init__()\n\n        self.gen = nn.Sequential(\n\n            create_gan_layer(z_dim,hidden_dim),\n            create_gan_layer(hidden_dim,hidden_dim*2),\n            create_gan_layer(hidden_dim*2,hidden_dim*4),\n            create_gan_layer(hidden_dim*4,hidden_dim*8),\n\n            nn.Linear(hidden_dim*8,image_dim),\n            nn.sigmoid()\n        )\n    \n    def forward(self,noise):\n        return self.gen(noise)",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Here  the intial linear defintion is just a intialization which creates the structure of the model . This is just for one iamge it ignore the batch_size or all the input samples. \nCalling the model by passing input with batch size to the variable it is assigned to during declaration . here it is gen(noise). Forward acts as the calling function once the object is created.\nhttps://stackoverflow.com/questions/54916135/what-is-the-class-definition-of-nn-linear-in-pytorch",
   "metadata": {
    "tags": [],
    "cell_id": "00012-be1218bc-a575-434a-a377-e193004db49c",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Creating&nbsp;Noise&nbsp;Generator",
   "metadata": {
    "tags": [],
    "cell_id": "00014-6c168c92-8089-499e-bc0f-f28155f3fc67",
    "deepnote_cell_type": "text-cell-h3"
   }
  },
  {
   "cell_type": "code",
   "source": "def noise_generator(num_samples,z_dim,device):\n\n    return torch.randn(num_samples,z_dim,device = device)",
   "metadata": {
    "tags": [],
    "cell_id": "00013-a3b4d1d5-3437-4036-801f-9e09168296f8",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "1486c72e",
    "execution_start": 1624452465610,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": "### The Discriminator",
   "metadata": {
    "tags": [],
    "cell_id": "00015-a7e4e91a-76d3-494c-9c49-83bb9f858f4a",
    "deepnote_cell_type": "text-cell-h3"
   }
  },
  {
   "cell_type": "code",
   "source": "def create_disc_layer(input_dim,output_dim):\n\n    return nn.Sequential(\n\n        nn.Linear(input_dim,output_dim),\n        nn.LeakyReLU(0.2,inplace=True)\n    )",
   "metadata": {
    "tags": [],
    "cell_id": "00015-1f5479dc-2f4c-44ca-8205-372b277375fc",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "db057759",
    "execution_start": 1624454869072,
    "execution_millis": 9,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "source": "class Discriminator(nn.Module):\n\n    def __init__(self,im_dim,1,device=device)",
   "metadata": {
    "tags": [],
    "cell_id": "00019-a043c902-dbe3-449b-b6c3-b11d8f9099e2",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=a5eebfae-950c-452c-bcd1-02b41e6a5850' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "b02f753b-6845-4d93-8fa8-18c027434829",
  "deepnote_execution_queue": []
 }
}