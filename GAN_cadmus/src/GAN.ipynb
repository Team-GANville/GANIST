{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "",
   "metadata": {
    "tags": [],
    "cell_id": "00002-a3960d36-4e23-4878-95ce-a809883232f0",
    "is_code_hidden": true,
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00002-d48aaa4f-e3c4-4bfd-80c2-fa21d30abf72",
    "is_code_hidden": false,
    "deepnote_to_be_reexecuted": false,
    "source_hash": "8ebf4d8d",
    "execution_start": 1624346689290,
    "execution_millis": 1,
    "deepnote_cell_type": "code"
   },
   "source": "# 1. batch_size :  The number of samples to train use in one iteration\n# 2. epochs : The number of times the network goes through the enitre training dataset.\n# 3. Sample_size : [speculation] The number of images[random noise] used in training for generator.\n# 4. nz :[speculation] input feature size for each sample[image] in above sample_size.\n# 5. k : hyper-parameter\n# 6. device : utilizing GPU if available ",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Dependencies",
   "metadata": {
    "tags": [],
    "cell_id": "00002-84fbcf29-7ceb-40cd-8c10-2131edae520e",
    "deepnote_cell_type": "text-cell-h2"
   }
  },
  {
   "cell_type": "markdown",
   "source": "1. Tqdm :  provides progress bar.\n2. Transform : provides common image transform algorithms.\n3. make_grid : Make a grid of images.\n4. DataLoader: helps in importing training and test sets ",
   "metadata": {
    "tags": [],
    "cell_id": "00003-be2aa102-9fc3-48a7-afee-0c87b9dd8365",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00009-36dedc80-7016-432e-8cab-d284b2ef7735",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4354564f",
    "execution_start": 1624346689298,
    "execution_millis": 1470,
    "deepnote_cell_type": "code"
   },
   "source": "import torch \nfrom torch import nn\nfrom tqdm.auto import tqdm\nfrom torchvision import transforms\nfrom torchvision.datasets import MNIST\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\ntorch.manual_seed(0)",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 2,
     "data": {
      "text/plain": "<torch._C.Generator at 0x7f34d5767c50>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "\nTensor:\n\n    1. Tensors are n-dimnesional matrix or vertices.\n    2. Pytorch use tensor operations.\n\nBatches:\n\n    1. Batches are the amount of training samples the model performs operation during a single execution.\n    2. Batch values are usually chosen to be multiples of 2 (32,64,128,256,512).\n",
   "metadata": {
    "tags": [],
    "cell_id": "00004-537e6a70-478b-4b63-9e18-56fc3313a624",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "# Dataset\n\n    1. The Dataset is downloaded from the MNIST website . Furtherthe data is divided\n       into batches , converted from PIL to tensors using DataLoaders.\n    2. Dataloader encloses a iterable wrapper over the tensor object using which we\n       can access each batch.\n    3. Structure : 469 batches -> each containg 128 images -> each image  [1,28,28]",
   "metadata": {
    "tags": [],
    "cell_id": "00006-03e85427-fae3-4240-a248-15b664a8257e",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00007-0c5e8c5c-b2ce-4c85-85d0-ffa2d69f7d2b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "80897178",
    "execution_start": 1624347427927,
    "execution_millis": 6,
    "deepnote_cell_type": "code"
   },
   "source": "loss_func = nn.BCEWithLogitsLoss()\nepochs = 200\nbatch_size = 128\nlr = 0.0001\nz_dim = 64\ndevice = 'cuda'",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00004-482a4e69-1bab-4f81-a5cc-a1503dc077b0",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "3713482c",
    "execution_start": 1624347359897,
    "execution_millis": 1996,
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "dataloader = DataLoader( MNIST(\"/work/basicGAN/GAN_cadmus/input\",download = True,transform = transforms.ToTensor() )\n                ,batch_size = batch_size , shuffle = True)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00009-79bf1256-722d-4406-8a4b-cbde57e66fae",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "fd8ef7e3",
    "execution_start": 1624347820822,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "source": "def show_tensor_images(image_tensor,num_images=25,size = (1,28,28)):\n\n    image_unflat = image_tensor.detach().cpu().view(-1, *size)\n    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n    plt.show()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00009-e692a332-f099-49f8-b942-0551dcd2ca9b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "1296db89",
    "execution_start": 1624352192781,
    "execution_millis": 11,
    "deepnote_cell_type": "code"
   },
   "source": "def create_gan(input_dim,output_dim):\n    \n    return nn.Sequential(\n\n        nn.Linear(input_dim,output_dim)\n        nn.BatchNorm1d(output_dim)\n        nn.LeakyReLU(inplace = False)\n    )",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-44-fa0097b9607f>, line 6)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-44-fa0097b9607f>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    nn.BatchNorm1d(output_dim)\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00011-53360c5f-6bc8-4870-aa2a-5564a25755a4",
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=a5eebfae-950c-452c-bcd1-02b41e6a5850' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "b02f753b-6845-4d93-8fa8-18c027434829",
  "deepnote_execution_queue": []
 }
}